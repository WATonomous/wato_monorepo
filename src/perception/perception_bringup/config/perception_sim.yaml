# Copyright (c) 2025-present WATonomous. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# =============================================================================
# Patchwork++ Node
# =============================================================================
/**/patchworkpp_node:
  ros__parameters:
    # Patchwork++ parameters (seeded from library defaults)
    base_frame: "base_link"
    num_iter: 5
    num_lpr: 20
    num_min_pts: 0
    th_seeds: 0.3
    th_dist: 0.15
    th_seeds_v: 0.25
    th_dist_v: 0.85
    max_range: 90.0
    min_range: 1.0
    uprightness_thr: 0.101
    enable_RNR: false
    verbose: false

    # QoS Configuration
    # Subscriber QoS: best_effort for low-latency sensor data (default for LiDAR)
    qos_subscriber_reliability: "best_effort"  # Options: "reliable", "best_effort"
    qos_subscriber_depth: 10                   # Queue depth for incoming messages

    # Publisher QoS: reliable + transient_local for immediate availability
    # Transient local ensures late-joining subscribers (e.g., RViz) receive the latest
    # segmentation immediately without waiting for the next scan
    qos_publisher_reliability: "reliable"      # Options: "reliable", "best_effort"
    qos_publisher_durability: "transient_local"  # Options: "transient_local", "volatile"
    qos_publisher_depth: 10                    # Queue depth for outgoing messages

# =============================================================================
# Multi-Camera Synchronization Node
# =============================================================================
multi_camera_sync:
  ros__parameters:
    # Camera topics to synchronize
    # For raw images, use topics like: ["/camera1/image_raw", "/camera2/image_raw"]
    # For compressed images, use topics like: ["/camera1/image_raw/compressed", "/camera2/image_raw/compressed"]
    camera_topics:
      - "/camera_lower_sw/image_rect"
      - "/camera_lower_ne/image_rect"
      - "/camera_lower_se/image_rect"
      - "/camera_lower_nw/image_rect"
      - "/camera_pano_ww/image_rect"
      - "/camera_pano_nn/image_rect"
      - "/camera_pano_ee/image_rect"
      - "/camera_pano_se/image_rect"
      - "/camera_pano_ne/image_rect"
      - "/camera_pano_nw/image_rect"
      - "/camera_pano_ss/image_rect"
      - "/camera_pano_sw/image_rect"

    # Optional names for the cameras (if not provided, will auto-generate camera_1, camera_2, etc.)
    camera_names:
      - "camera_lower_sw"
      - "camera_lower_ne"
      - "camera_lower_se"
      - "camera_lower_nw"
      - "camera_pano_ww"
      - "camera_pano_nn"
      - "camera_pano_ee"
      - "camera_pano_se"
      - "camera_pano_ne"
      - "camera_pano_nw"
      - "camera_pano_ss"
      - "camera_pano_sw"

    # Whether to use compressed images (sensor_msgs/CompressedImage) instead of raw (sensor_msgs/Image)
    # Set to true if your camera topics publish compressed images
    use_compressed: false

    # Maximum time difference in milliseconds for message synchronization
    # Larger values allow more tolerance but may reduce temporal accuracy
    sync_tolerance_ms: 33.0

    # Queue size for message filters
    # Larger values can handle more variable frame rates but use more memory
    queue_size: 10

    # Whether to publish synchronization information and statistics
    publish_sync_info: true

    # IPC-specific optimizations
    use_intra_process_comms: true

    # QoS settings optimized for camera data with IPC
    qos_depth: 5
    qos_reliability: "best_effort"  # reliable or "best_effort" for higher throughput
    qos_durability: "volatile"
    qos_history: "keep_last"

# =============================================================================
# Deep Object Detection Node
# =============================================================================
/**/deep_object_detection_node:
  ros__parameters:
    model_path: "/ws/models/models/yolov8m.onnx"
    class_names_path: "/ws/src/deep_ros/deep_object_detection/config/coco_classes.txt"
    use_compressed_images: true  # Set to true for compressed images, false for uncompressed (shared memory)

    Model:
      num_classes: 80
      bbox_format: "cxcywh"
      output_shape: [1, 84, 8400]

    Preprocessing:
      input_width: 640
      input_height: 640
      normalization_type: "scale_0_1"
      mean: [0.0, 0.0, 0.0]
      std: [1.0, 1.0, 1.0]
      resize_method: "letterbox"
      pad_value: 114
      color_format: "rgb"

    Postprocessing:
      score_threshold: 0.65
      nms_iou_threshold: 0.45
      score_activation: "sigmoid"
      enable_nms: true
      class_score_mode: "all_classes"
      class_score_start_idx: -1
      class_score_count: -1

      layout:
        batch_dim: 0
        detection_dim: 2
        feature_dim: 1
        bbox_start_idx: 0
        bbox_count: 4
        score_idx: 4
        class_idx: 5

    Backend:
      plugin: "onnxruntime_gpu"
      execution_provider: "tensorrt"
      device_id: 0
      trt_engine_cache_enable: true
      trt_engine_cache_path: "/tmp/deep_ros_ort_trt_cache"
